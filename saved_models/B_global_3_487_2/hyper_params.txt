epochs: 2000
patience: 600
dropout: 0.1
learning rate: 0.0001
batch size: 25833
optimizer: adam
dataset: HFO + distractor
load_model: False
detrend: True
normalize: <function normalize at 0x7fe9cdb4b840>
kfold: False
class_weights: None
testing: True
num_epochs_ran: 2000
num classes: 2
dense_num: 10
eps: 1e-07
size: 100
nonlin: selu
nonlin_out: sigmoid
identifier: 487
filters: [48, 96]
kernel_size: [20, 10]
