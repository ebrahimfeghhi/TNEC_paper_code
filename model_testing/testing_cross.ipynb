{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook test models for the global experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "from tensorflow.keras.layers import MaxPooling1D, AveragePooling1D, BatchNormalization, UpSampling1D, Reshape, LSTM\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv1D, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import detrend\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from model_defined import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detrend_func(X):  \n",
    "    \n",
    "    X_raw = X[:, :, 0]\n",
    "    X_raw_detrend = detrend(X_raw)\n",
    "    X[:, :, 0] = X_raw_detrend\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_models(model_name, model_path, iter_list):\n",
    "    \n",
    "    model_arr=[]\n",
    "    \n",
    "    # load models and store models in model_arr\n",
    "    \n",
    "    for i in iter_list:\n",
    "        print(i)\n",
    "        load_model_path = model_path + model_name + str(i)\n",
    "        model_best = tf.keras.models.load_model(load_model_path + \"/best_model.h5\", \n",
    "                custom_objects={'FlipGradient':FlipGradient, 'binary_crossentropy_mask':binary_crossentropy_mask, 'mean_absolute_error_mask':mean_absolute_error_mask,\n",
    "                               'binary_acc':binary_acc})\n",
    "        model_arr.append(model_best)\n",
    "        \n",
    "    return model_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = '489' \n",
    "gsl = 'A' # gold standard label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home3/ebrahim/results/test_detector/cnn/final_models/'\n",
    "model_name = gsl + '_global_3_sigmoid_' + p + '_'\n",
    "iter_list = np.arange(1,2)\n",
    "model = load_models(model_name, model_path, iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_on_data(test_data_path, test_labels_path, model_arr, detrend_bool, domain_mode):\n",
    "    \n",
    "    X = np.load(test_data_path)\n",
    "    y = np.load(test_labels_path)\n",
    "    \n",
    "    if detrend_bool:\n",
    "        X= detrend_func(X)\n",
    "    \n",
    "    X_test = X[y==1]\n",
    "    perf_arr = np.zeros(len(model_arr))\n",
    "    \n",
    "    for i in range(len(model_arr)):\n",
    "        if domain_mode:\n",
    "            _, y_pred_label, = model_arr[i].predict(X_test)\n",
    "            y_pred_label[y_pred_label>.5] = 1\n",
    "            y_pred_label[y_pred_label!=1] = 0\n",
    "            perf_arr[i] = np.count_nonzero(y_pred_label)/y_pred_label.shape[0]\n",
    "        else:\n",
    "            y_pred_label = model_arr[i].predict(X_test)\n",
    "            y_pred_label_int = np.argmax(y_pred_label, axis=-1)\n",
    "            perf_arr[i] = np.count_nonzero(y_pred_label_int)/y_pred_label.shape[0]\n",
    "       \n",
    "\n",
    "    return perf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92268695]\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home3/ebrahim/ripple_code/yasa_labels/weighted_labels/' \n",
    "fname = 'global/'\n",
    "test_data_path = base_path + fname + 'X_test_all_3_' + p + '_' + gsl + '.npy'\n",
    "test_labels_path = base_path + fname + 'y_test_all_3_'  + p + '_' + gsl + '.npy'\n",
    "perf_arr = test_on_data(test_data_path, test_labels_path, model, True, False)\n",
    "print(perf_arr)\n",
    "#np.save('/home3/ebrahim/results/updated_results/global_nc/nc_' + p + '_' + gsl + '_gold.npy', perf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_data_path = base_path + fname + 'X_' + p + '_A.npy'\n",
    "test_labels_path = base_path + fname + 'y_' + p + '_A.npy'\n",
    "perf_arr = test_on_data(test_data_path, test_labels_path, model, True, False) / normalizer\n",
    "print(np.mean(perf_arr))\n",
    "#np.save('/home3/ebrahim/results/updated_results/global_nc/nc_' + p + '_' + gsl + '_A.npy', perf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189794845979528\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_path = base_path + fname + 'X_' + p + '_B.npy'\n",
    "test_labels_path = base_path + fname + 'y_' + p + '_B.npy'\n",
    "perf_arr = test_on_data(test_data_path, test_labels_path, model, True, False) / normalizer\n",
    "print(np.mean(perf_arr))\n",
    "\n",
    "#np.save('/home3/ebrahim/results/updated_results/global_nc/nc_' + p + '_' + gsl + '_B.npy', perf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8127175213629542\n"
     ]
    }
   ],
   "source": [
    "test_data_path = base_path + fname + 'X_' + p + '_C.npy'\n",
    "test_labels_path = base_path + fname + 'y_' + p + '_C.npy'\n",
    "perf_arr = test_on_data(test_data_path, test_labels_path, model, True, False) / normalizer\n",
    "print(np.mean(perf_arr))\n",
    "#np.save('/home3/ebrahim/results/updated_results/global_nc/nc_' + p + '_' + gsl + '_C.npy', perf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasEB",
   "language": "python",
   "name": "keraseb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
