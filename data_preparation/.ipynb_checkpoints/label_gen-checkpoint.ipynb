{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This notebook computes the three metrics (rel power, corr, rms) for 100ms iEEG windows\n",
    "# These features are taken from the YASA algorithm, written by Rapheal Vallant, and adopted for HFO detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "from mne.filter import resample\n",
    "from mne.filter import filter_data as filter_data_mne\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import detrend\n",
    "import yasa\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "np.random.seed(42)\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home3/ebrahim/ripple_code/yasa_labels/prepare_data/')\n",
    "from helper_functions import * \n",
    "from create_dat_helper import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(side, patient, file, factor, freq_broad=[1,250], portion=[]):\n",
    "    \n",
    "        time = np.asarray(h5py.File('/home3/ebrahim/ephys_data/' + patient + 'lfpTimeStamps.mat')['timeStamps'])\n",
    "    \n",
    "        # load file\n",
    "        if (side == 'L'):\n",
    "            data = data_loader(path='/home3/ebrahim/ephys_data/' + patient + 'LAH_Data', fileNum=file, fileType='L', patient=patient)\n",
    "            data, time_downsampled, fs = downsample(data = data, time=time, fileNum=file, factor=factor)\n",
    "          \n",
    "        else:\n",
    "            data = data_loader(path='/home3/ebrahim/ephys_data/' + patient + 'RAH_Data', fileNum=file, fileType='R', patient=patient)\n",
    "            data, time_downsampled, fs = downsample(data = data, time=time, fileNum=file, factor=factor)\n",
    "        \n",
    "        #data = filter_data_mne(data, fs, freq_broad[0], freq_broad[1], method='fir', verbose=0)\n",
    "        \n",
    "        if len(portion) != 0:\n",
    "            \n",
    "            lower = int(data.shape[0] * portion[0])\n",
    "            upper = int(data.shape[0] * portion[1])\n",
    "            \n",
    "            return data[lower:upper], fs\n",
    "        \n",
    "        return data, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spect_labels(data_full, portion, freq_broad=[20,250], sf=1000):\n",
    "    \n",
    "    \n",
    "    if portion == None:\n",
    "        data = data_full\n",
    "    else:\n",
    "        lr = portion[0]\n",
    "        ur = portion[1]\n",
    "        data = data_full[lr:ur]\n",
    "        \n",
    "    \n",
    "    # --------- Spect Labels -----------\n",
    "    f, t_spect, Sxx = yasa.main.stft_power(data, sf, window=.1, step=.025, band=freq_broad, norm=True, interp=False)\n",
    "    \n",
    "    idx_ripple = np.logical_and(f >= 75, f <= 125)\n",
    "    rel_pow = Sxx[idx_ripple].sum(0)\n",
    "    \n",
    "    return rel_pow, t_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def corr_labels(data_full, portion, sf=1000, detrend_bool=True):\n",
    "    \n",
    "    if portion == None:\n",
    "        data = data_full\n",
    "    else:\n",
    "        lr = portion[0]\n",
    "        ur = portion[1]\n",
    "        data = data_full[lr:ur]\n",
    "        \n",
    "        \n",
    "    # -------- Corr Labels -------------\n",
    "    data_ripple = filter_data_mne(data, sf, 75, 125, l_trans_bandwidth=1.5, \n",
    "                         h_trans_bandwidth=1.5, method='fir', verbose=0)\n",
    "    times = np.arange(data_ripple.shape[0])\n",
    "    \n",
    "    # Detrends each window individually\n",
    "    if detrend_bool:\n",
    "        \n",
    "        # break data into segments, and detrend raw signal \n",
    "        times, dat = yasa.sliding_window(data, sf=1000, window=.10, step=.025)\n",
    "        times, rb = yasa.sliding_window(data_ripple, sf=1000, window=.10, step=.025)\n",
    "        rb = np.ravel(rb)\n",
    "        dat_detrend = np.ravel(detrend(dat))\n",
    "        \n",
    "        # some data may be lost in this process, add it back\n",
    "        last_val = np.ravel(dat)[-1] # store last data point in detrended signal\n",
    "        last_ind = np.squeeze(np.argwhere(data==last_val)) # locate the index of this datapoint in original raw signal \n",
    "        dat_detrend = np.concatenate((dat_detrend, data[last_ind + 1:]))\n",
    "        rb = np.concatenate((rb, data_ripple[last_ind + 1:]))\n",
    "\n",
    "        t, mcorr = yasa.moving_transform(dat_detrend, rb, sf, window=.1, step=.1, method='corr', interp=False)\n",
    "         \n",
    "        t = t/4.0 + .025\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        t, mcorr = yasa.main.moving_transform(data, data_ripple, sf, window=.1, step=.025, method='corr', interp=False)\n",
    "   \n",
    "    return mcorr, t, data_ripple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rms_labels(data_full, data_ripple, portion, sf=1000):\n",
    "    \n",
    "    if portion == None:\n",
    "        data = data_full\n",
    "    else:\n",
    "        lr = portion[0]\n",
    "        ur = portion[1]\n",
    "        data = data_full[lr:ur]\n",
    "        \n",
    "    # -------- RMS Labels -------------\n",
    "    t, mrms = yasa.main.moving_transform(data_ripple, data, sf, window=.1, step=.025, method='rms', interp=False)   \n",
    "    \n",
    "    return mrms, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    \n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, shift, time_scale):\n",
    "    \n",
    "    \n",
    "    y = 1 / (1 + np.exp(-(x-shift)/time_scale))\n",
    "    \n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inverse_sigmoid(y, shift, time_scale):\n",
    "    \n",
    "    denom = 1-y\n",
    "    denom[denom==0] = 1e-6\n",
    "    \n",
    "    x = time_scale * np.log(y/denom) + shift \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric_to_prob(**kwargs):\n",
    "    \n",
    "    for key in kwargs.keys():\n",
    "        \n",
    "        \n",
    "        if key == 'spect':\n",
    "            \n",
    "            rel_pow = kwargs['spect']\n",
    "            \n",
    "            rel_pow_probs = sigmoid(rel_pow*100, shift=15.0, time_scale=4.0)\n",
    "            \n",
    "         \n",
    "        if key == 'corr':\n",
    "            \n",
    "            corr = kwargs['corr']\n",
    "            \n",
    "            corr_probs = sigmoid(corr*100, shift=45.0, time_scale=4.0)\n",
    "            \n",
    "        if key == 'rms':\n",
    "            \n",
    "            rms = kwargs['rms']\n",
    "            \n",
    "            # change to continuous function mapping \n",
    "            trimmed_std = yasa.main.trimbothstd(rms, cut=0.001)\n",
    "            \n",
    "            thresh_rms = mrms.mean() + 3 * trimmed_std\n",
    "            \n",
    "            rms_probs = sigmoid(rms, thresh_rms, trimmed_std)\n",
    "\n",
    "            \n",
    "    return rel_pow_probs, corr_probs, rms_probs, trimmed_std, thresh_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_align(idx_spect, idx_corr, idx_rms, t_spect, t_corr, t_rms, win_size, hop_size):\n",
    "    \n",
    "    cut = int(win_size / hop_size) # size of indices to cut from both sides\n",
    "    \n",
    "    # cut an extra index b/c spect is one dimension longer \n",
    "    idx_spect = idx_spect[cut:-cut-1] \n",
    "    t_spect = t_spect[cut:-cut-1]\n",
    "    \n",
    "    idx_rms = idx_rms[cut:-cut]\n",
    "    t_rms = t_rms[cut:-cut]\n",
    "    \n",
    "    idx_start = find_nearest(t_corr, t_rms[0])\n",
    "    idx_end = find_nearest(t_corr, t_rms[-1])\n",
    "\n",
    "    idx_corr = idx_corr[idx_start:idx_end+1]\n",
    "    t_corr = t_corr[idx_start:idx_end+1]\n",
    "    \n",
    "    if np.shape(idx_spect) == np.shape(idx_corr) == np.shape(idx_rms):\n",
    "        print(\"Success\")\n",
    "    else:\n",
    "        print(\"Shape mismatch\")\n",
    "    \n",
    "    diff_spect_corr = np.mean(np.subtract(t_spect, t_corr))\n",
    "    diff_spect_rms = np.mean(np.subtract(t_spect, t_rms))\n",
    "    diff_rms_corr = np.mean(np.subtract(t_rms, t_corr))\n",
    "    \n",
    "    if diff_spect_corr <= 1e-4:\n",
    "        if diff_spect_rms <= 1e-4:\n",
    "            if diff_rms_corr <= 1e-4:\n",
    "                print(\"Times Success\")\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        \n",
    "    return idx_spect, idx_corr, idx_rms, t_spect, t_corr, t_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_mat(**kwargs):\n",
    "    \n",
    "    label_matrix_orig = np.vstack(list(kwargs.values())).T\n",
    "    \n",
    "    return label_matrix_orig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_logits(probas, shift_rms, scale_rms):\n",
    "    \n",
    "    label_mat_logits = np.zeros_like(probas)\n",
    "    \n",
    "    label_mat_logits[:, 0] = inverse_sigmoid(probas[:, 0], shift=15.0, time_scale=4.0) / 100.\n",
    "    label_mat_logits[:, 1] = inverse_sigmoid(probas[:, 1], shift=45.0, time_scale=4.0) / 100.\n",
    "    label_mat_logits[:, 2] = inverse_sigmoid(probas[:, 2], shift_rms, scale_rms)\n",
    "    \n",
    "    # check to make sure function works \n",
    "    #if np.mean(np.subtract(sigmoid(label_mat_logits[:, 2], shift_rms, scale_rms), probas[:, 2])) < 1e-4: \n",
    "    #    if np.mean(np.subtract(sigmoid(label_mat_logits[:, 1], shift_rms, scale_rms), probas[:, 1])) < 1e-4: \n",
    "    #        if np.mean(np.subtract(sigmoid(label_mat_logits[:, 0], shift_rms, scale_rms), probas[:, 0])) < 1e-4: \n",
    "    #            print(\"LOGITS LOOK GOOD\")\n",
    "\n",
    "    \n",
    "    return label_mat_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data(data, data_ripple, label_matrix, label_mat_orig, t, nonripple_num, feature, logits, shift_rms, scale_rms):\n",
    "   \n",
    "\n",
    "    # evenly sample data from windows which have feature value of >.5, and windows which have feature value <.5\n",
    "    if feature != None: \n",
    "        \n",
    "        desired_feature = label_mat_orig[:, feature]\n",
    "        ripples_indices = np.argwhere(desired_feature> .5)\n",
    "        nonripples_indices_big = np.argwhere(desired_feature < .5)\n",
    "        selected_nonripples = rng.choice(nonripples_indices_big.shape[0], ripples_indices.shape[0], replace=False)\n",
    "        nonripples_indices = nonripples_indices_big[selected_nonripples]\n",
    "        \n",
    "        label_mat_orig = label_mat_orig[:, feature]\n",
    "\n",
    "    else:\n",
    "        ripples_indices = np.argwhere(label_matrix > .5)\n",
    "        nonripples_indices_big = np.argwhere(label_matrix < .5)\n",
    "        selected_nonripples = rng.choice(nonripples_indices_big.shape[0], ripples_indices.shape[0], replace=False)\n",
    "        nonripples_indices = nonripples_indices_big[selected_nonripples]\n",
    "\n",
    "    # multiply by 1000 to convert to ms, data is sampled at 1000 Hz \n",
    "    ripple_times = t[ripples_indices] * 1000 \n",
    "    nonripple_times = t[nonripples_indices] * 1000\n",
    "\n",
    "    ripples = []\n",
    "    nonripples = []\n",
    "\n",
    "    data_full = np.vstack((data, data_ripple)).T\n",
    "\n",
    "    print(data_full.shape)\n",
    "\n",
    "    for r in ripple_times:\n",
    "        ripples.append(data_full[int(r)-50:int(r)+50,:])\n",
    "\n",
    "    for n in nonripple_times:\n",
    "        nonripples.append(data_full[int(n)-50:int(n)+50,:])\n",
    "\n",
    "    # data\n",
    "    if (len(ripples) != 0):\n",
    "        ripple_dat = np.stack(ripples)\n",
    "        nonripple_data = np.stack(nonripples)\n",
    "\n",
    "    data_list = [ripple_dat, nonripple_data]\n",
    "\n",
    "    if logits:\n",
    "        label_mat_logits = to_logits(label_mat_orig, shift_rms, scale_rms)\n",
    "        ripple_labels = label_mat_logits[ripples_indices]\n",
    "        nonripple_labels = label_mat_logits[nonripples_indices]\n",
    "      \n",
    "    else: \n",
    "        ripple_labels = label_mat_orig[ripples_indices]\n",
    "        nonripple_labels = label_mat_orig[nonripples_indices]\n",
    "\n",
    "    labels_list = [ripple_labels, nonripple_labels]\n",
    "\n",
    "    return data_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_small(data, data_ripple, t, labels):\n",
    "    \n",
    "    data_full = np.vstack((data, data_ripple)).T\n",
    "    t_sec = t * 1000\n",
    "    data_labeled = []\n",
    "    \n",
    "    for r in t_sec:\n",
    "        data_labeled.append(data_full[int(r)-50:int(r)+50,:])\n",
    "    \n",
    "    \n",
    "    return data_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_data(data, labels, path, name):\n",
    "    \n",
    "    X = data\n",
    "    y = labels\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    np.save(save_path + 'X_' + name, X)\n",
    "    np.save(save_path + 'y_' + name, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ripples_list = []\n",
    "ripples_labels = []\n",
    "\n",
    "nonevents_list = []\n",
    "nonevents_labels = []\n",
    "\n",
    "data_total = []\n",
    "labels_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists:  True\n",
      "/home3/ebrahim/ephys_data/509_files/RAH_Data/GA2-RAH1_0004.mat has been added.\n"
     ]
    }
   ],
   "source": [
    "data, sf = load_data('R', '509_files/', file=1, factor=32, portion=[]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home3/ebrahim/R_509_1', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists:  True\n",
      "/home3/ebrahim/ephys_data/509_files/RAH_Data/GA2-RAH1_0004.mat has been added.\n",
      "Std raw signal:  1.0406940100613258\n",
      "Mean raw signal:  0.0038574731992826326\n",
      "Sampling frequency:  1000.072484501669\n",
      "Success\n",
      "Times Success\n"
     ]
    }
   ],
   "source": [
    "#num_files = [1,2,3,4,5,6,7,8]\n",
    "num_files = [1]\n",
    "factor = 32 # 32 for 509, 40 for 489, 487, 493\n",
    "feature = 1 # set to None if want to use average of all labels\n",
    "logits = True # if false, will convert to probability using shifted sigmoid \n",
    "pre_normalize = True\n",
    "patient = '509'\n",
    "\n",
    "for f in num_files:\n",
    "    \n",
    "    # load data\n",
    "    data, sf = load_data('R', patient + '_files/', file=f, factor=factor, portion=[]) \n",
    "     \n",
    "    if pre_normalize:\n",
    "        data = RobustScaler().fit_transform(np.expand_dims(data,axis=-1))\n",
    "        data = np.squeeze(data)\n",
    "        print(\"Std raw signal: \", np.std(data))\n",
    "        print(\"Mean raw signal: \", np.mean(data))\n",
    "    \n",
    "    print(\"Sampling frequency: \", sf)\n",
    "    \n",
    "    # comptue metric for each epoch\n",
    "    rel_pow, t_spect = spect_labels(data, None)\n",
    "    mcorr, t_corr, data_ripple = corr_labels(data, None)\n",
    "    mrms, t_rms = rms_labels(data, data_ripple, None)\n",
    "\n",
    "    # align times\n",
    "    spect_idx, corr_idx, rms_idx, t_s, t_c, t_r = time_align(rel_pow, mcorr, mrms, t_spect, t_corr, t_rms, win_size=.1, hop_size=.025)    \n",
    "    \n",
    "    # arrange label matrix\n",
    "    label_mat_orig = label_mat(spect = spect_idx, corr = corr_idx, rms = rms_idx) \n",
    "\n",
    "    # load data and corresponding labels\n",
    "    data_list = create_data_small(data, data_ripple, t_c, label_mat_orig) \n",
    "    \n",
    "    data_total.append(data_list)\n",
    "    labels_total.append(label_mat_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/home3/ebrahim/hfo_consistency_package/single_channel', data)\n",
    "np.save('/home3/ebrahim/hfo_consistency_package/single_channel_features', label_mat_orig)\n",
    "np.save('/home3/ebrahim/hfo_consistency_package/single_channel_times', t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments = np.stack(data_list)[:, :, 0]\n",
    "segments_raveled_nooverlap = np.ravel(segments[::4])\n",
    "print(data.shape[0] - segments_raveled_nooverlap.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "y_rel_quantile = stats.rankdata(label_mat_orig[:,0], \"average\")/len(label_mat_orig[:,0])\n",
    "y_corr_quantile = stats.rankdata(label_mat_orig[:,1], \"average\")/len(label_mat_orig[:,1])\n",
    "y_rms_quantile = stats.rankdata(label_mat_orig[:,2], \"average\")/len(label_mat_orig[:,2])\n",
    "\n",
    "y_quantile = np.vstack((y_rel_quantile, y_corr_quantile, y_rms_quantile)).T\n",
    "Ascores = np.average(y_quantile, axis=-1, weights=(1,3,1))\n",
    "transients = np.argwhere(Ascores > .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1800100.0000000002\n"
     ]
    }
   ],
   "source": [
    "t_sec = t_c * 1000\n",
    "t_sec_fourth = int(t_sec.shape[0]/4)\n",
    "t_start = t_sec[0] - 100\n",
    "print(t_start)\n",
    "t_end = t_sec[t_sec_fourth] + 50\n",
    "print(t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5399900.0\n",
      "7199950.0\n"
     ]
    }
   ],
   "source": [
    "t_start = t_sec[t_sec_fourth*3] - 100\n",
    "print(t_start)\n",
    "t_end = t_sec[-1] + 50\n",
    "print(t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats \n",
    "\n",
    "data_red = data[int(t_start):int(t_end)]\n",
    "labels = label_mat_orig[:t_sec_fourth]\n",
    "#labels = y_quantile[t_sec_fourth*3:]\n",
    "\n",
    "transient_ind = np.argwhere(np.average(labels , axis=-1, weights=[1,3,1])>.9)\n",
    "print(transient_ind.shape)\n",
    "np.save('/home3/ebrahim/hfo_consistency_package/example_data/S1_start_stop', data_red)\n",
    "np.save('/home3/ebrahim/hfo_consistency_package/example_data/S1_transient_ind', transient_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('weighted_labels/' + patient + '/RL_' + patient + '_3_data_normalized', np.vstack(data_total))\n",
    "np.save('weighted_labels/' + patient + '/RL_' + patient + '_3_labels_normalized', np.vstack(labels_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22144, 100, 2)\n",
      "(22144, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "# save data\n",
    "save_path = '/home3/ebrahim/ripple_code/yasa_fold/deep_learning/sp/'\n",
    "name = 'nonevents_train_even_channels'\n",
    "save_data(np.vstack(nonevents_list), np.vstack(nonevents_labels), save_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29920, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_dist_5_LR.shape)\n",
    "np.save('deep_learning/train/X_train_dist_include_5', X_train_dist_5_LR)\n",
    "np.save('deep_learning/train/y_train_dist_include_5', y_train_dist_5_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# save label matrix and label_matrix_orig\n",
    "np.save('label_mat_509_L_5', label_matrix)\n",
    "np.save('label_mat_509_L_5_orig', label_mat_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "transients_labels_2 = []\n",
    "for l in transients_labels:\n",
    "    l = np.expand_dims(l, axis=-1)\n",
    "    transients_labels_2.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripples shape:  (4772, 100, 2)\n",
      "Ripples labels shape:  (4772, 1)\n",
      "Transients shape:  (32778, 100, 2)\n",
      "Transients labels shape:  (32778, 1)\n",
      "Nonevents shape:  (9544, 100, 2)\n",
      "Nonevents labels shape:  (9544, 1)\n"
     ]
    }
   ],
   "source": [
    "ripples_509 = np.vstack(ripples_list)\n",
    "ripples_labels_509 = np.vstack(ripples_labels)\n",
    "\n",
    "transients_509 = np.vstack(transients_list)\n",
    "transients_labels_509 = np.vstack(transients_labels_2)\n",
    "\n",
    "nonevents_509 = np.vstack(nonevents_list)\n",
    "nonevents_labels_509 = np.vstack(nonevents_labels)\n",
    "\n",
    "print(\"Ripples shape: \", ripples_509.shape)\n",
    "print(\"Ripples labels shape: \", ripples_labels_509.shape)\n",
    "print(\"Transients shape: \", transients_509.shape)\n",
    "print(\"Transients labels shape: \", transients_labels_509.shape)\n",
    "print(\"Nonevents shzape: \", nonevents_509.shape)\n",
    "print(\"Nonevents labels shape: \", nonevents_labels_509.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(label_mat_orig[0:10, :])\n",
    "print(corr_idx[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(label_matrix)\n",
    "np.save('labels_matrix_509_L_5', label_matrix)\n",
    "np.save('labels_matrix_orig_509_L_5', label_mat_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# select and save portion of nonevents\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "np.save('deep_learning/nonevents', nonevents_509)\n",
    "np.save('deep_learning/nonevents_labels', nonevents_labels_509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.save('deep_learning/sp/ripples_509', ripples_509)\n",
    "np.save('deep_learning/sp/transients_509', transients_509)\n",
    "np.save('deep_learning/sp/nonevents_509', nonevents_509)\n",
    "np.save('deep_learning/sp/ripples_509_labels', ripples_labels_509)\n",
    "np.save('deep_learning/sp/transients_509_labels', transients_labels_509)\n",
    "np.save('deep_learning/sp/nonevents_509_labels', nonevents_labels_509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train_509_L_5 = np.vstack((ripples_509, transients_509, nonevents_509))\n",
    "y_train_509_L_5 = np.vstack((ripples_labels_509, transients_labels_509,nonevents_labels_509))\n",
    "\n",
    "np.save('training_set/X_train_509_L_5', X_train_509_L_5)\n",
    "np.save('training_set/y_train_509_L_5', y_train_509_L_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "r = np.load('backup/ripples_509.npy')\n",
    "t = np.load('backup/transients_509.npy')\n",
    "n = np.load('backup/nonevents_509.npy')\n",
    "rl = np.load('backup/ripples_509_labels.npy')\n",
    "tl = np.load('backup/transients_509_labels.npy')\n",
    "nl = np.load('backup/nonevents_509_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack((r, t, n))\n",
    "y_train = np.vstack((rl, tl,nl))\n",
    "\n",
    "np.save('training_set/X_train', X_train)\n",
    "np.save('training_set/y_train', y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasEB",
   "language": "python",
   "name": "keraseb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
